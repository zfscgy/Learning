# 隐马尔科夫模型

## 定义

$X_n$ 是一个Markov过程，$Y_n = f(X_n) $ ，那么 $Y_n$ 是一个隐Markov过程。

## Filtering

**已经知道 $X_n​$ 的状态转移矩阵（transition probabilities），以及 $Y_n​$ 关于 $X_n​$ 的条件概率 $P(Y_n|X_n)​$ （emission distributions），求 $ x_n​$ 在 $y_n, y_{n-1}, .... y_1​$下的条件概率分布，即  $p(x_n|y_1,...,y_n) = p(x_n|y_{1:n})​$**

利用forward算法：

$p(x_n, y_{1:n}) = \sum\limits_{x_{n-1}} p(x_{n-1}, x_n, y_{1:n}) = \sum\limits_{x_{n-1}} p(y_n|x_n, x_{n-1}, _{1:n-1})p(x_n|x_{n-1}, y_{1:n-1}) \cdot p(x_{n-1}, y_{1:n-1})\\ = p(y_n|x_n) \sum\limits_{x_{n-1}}  p(x_n|x_{n-1}) \cdot p(x_{n-1}, y_{1:n})​$  

因此可以从 $p(x_1, y_1)$ 递推得到 $p(x_n, y_{1:n})$

$p(x_n|y_{1:n}) = \dfrac{p(x_n, y_{1:n})}{p(y_{1:n})} =  \dfrac{p(x_n, y_{1:n})}{\sum_{x_n} p(x_n, y_{1:n})} ​$

## Smoothing

**已经知道 $X_n$ 的状态转移矩阵（transition probabilities），以及 $Y_n$ 关于 $X_n$ 的条件概率 $P(Y_n|X_n)$ （emission distributions），求 $ x_t$ 在 $y_n, y_{n-1}, .... y_1$下的条件概率分布，即  $p(x_t|y_1,...,y_n) = p(x_t|y_{1:n})$** ，其中 $t < n$

利用forward-backward算法：

首先，$p(x_t|y_{1:t}) ​$ 可以根据 forward 算法求得

然后有 $p(y_{t+1:n}|x_t)​$ 可以根据backward算法求得（见下面Note）

于是有$p(x_t, y_{1:n}) = p(x_t, y_{1:t}, y_{t+1:n}) =p(y_{t+1:n}|x_t) \cdot  p(x_t, y_{1:t})​$

## Note

###forward

在递推 $p(x_n, y_{1:n})​$ 的时候，$y_{1:n}​$ 是我们已经观测到的变量，因此我们要计算的，实际上是不同的 $x_n​$的概率，如：$p(x_n=1|y_{1:n}),\ p(x_n=2|y_{1:n})​$。因此forward算法中的表达式可以写成 

$\begin{bmatrix} p(x_n = 1, y_{1:n}) \\ p(x_n=2,y_{1:n})\\... \end{bmatrix} =\\ 
\begin{bmatrix} p(y_n|x_n = 1) & 0&0\\ 0 & p(y_n|x_n=2) & 0 \\ 0  & 0 & ...\end{bmatrix}
\begin{bmatrix} p(x_n = 1|x_{n-1} = 1) & p(x_n = 1|x_{n-1} = 2) &  ... \\o(x_n = 2|x_{n-1} = 1) & p(x_n=2|x_{n-1} = 2) & ... \\ ... & ... & ... \end{bmatrix} 
\begin{bmatrix} p(x_{n-1} = 1,y_{1:n-1}) \\ p(x_{n-1} = 2,y_{1:n-1}) \\ ... \end{bmatrix}​$

如果把 $\begin{bmatrix} p(x_n = 1, y_{1:n}) \\ p(x_n=2,y_{1:n})) \\... \end{bmatrix}  ​$ 记作 $\mathbf{f_{0:n}}​$，$\begin{bmatrix} p(y_n|x_n = 1) & 0&0\\ 0 & p(y_n|x_n=2) & 0 \\ 0  & 0 & ...\end{bmatrix}​$ 记作 $\large\mathbf{O_{y_n}}​$

那么有：$\mathbf{f_{0:n}} = \mathbf{O_{y_{n}}} T^t \mathbf {f_{0:n-1}}​$，其中 $T^t​$ 是$X_n​$ 的转移矩阵（transition matrix）的转置。其中，$\mathbf{f_{0:0}}​$ 是$X_0​$ 的状态分布，可以看做是初始状态分布。

此推导过程在[维基百科：Forward-backward algorithm](https://en.wikipedia.org/wiki/Forward–backward_algorithm) 阐述了，但由于个人感觉维基百科上的推导写的不是很清晰，因此重新推导了一遍。

###backward

在递推 $p(y_{t+1:n}| x_t)$ 的时候，考虑 $p(y_{t:n}|x_{t-1}) = \sum_{x_t}p(y_{t}, y_{t+1:n}, x_t| x_{t-1})$

其中，$p(y_{t}, y_{t+1:n}, x_t |x_{t-1}) = p(y_t|x_t)\cdot p(x_t|x_{t-1}) \cdot p(y_{t+1:n}|x_t)​$

于是类似forward算法的推导，backward算法的表达式可以写成

$\begin{bmatrix} p(y_{t:n}|x_{t-1}=1) \\ p(y_{t:n}|x_{t-1}=2)\\...\end{bmatrix} = 
\begin{bmatrix}p(x_t = 1|x_{t-1} = 1) & p(x_t = 2|x_{t-1} = 1) &  ... \\p(x_t = 1|x_{t-1} = 2) & p(x_t=2|x_{t-1} = 2) & ... \\ ... & ... & ... \end{bmatrix}
\begin{bmatrix}y_t|x_t=1 & 0 & 0 \\ 0 & y_t|x_t=2 & 0\\ 0 & 0 & ...\end{bmatrix}
\begin{bmatrix}p(y_{t+1:n}|x_t=1) \\ p(y_{t+1:n}|x_t=2) \\ ...\end{bmatrix}$

我们把 $\begin{bmatrix}p(y_{t+1:n}|x_t=1) \\ p(y_{t+1:n}|x_t=2) \\ ...\end{bmatrix}​$ 记作 $\mathbf{b_{t:n}}​$，则有 $\mathbf{b_{t:n}} = T\mathbf{O_{y_t}}\mathbf{b_{t+1:n}}​$

其中，$\mathbf{b_{n-1:n}} = p(y_n|x_{n-1}) = T\mathbf{O_{y_n}}   \begin{bmatrix}1\\1\\...\end{bmatrix}$， 我们可以把最后一项 $\mathbf{1}$ 记作 $\mathbf{b_{n:n}}$

### Smoothing

根据前面提到的$p(x_t, y_{1:n}) = p(x_t, y_{1:t}, y_{t+1:n}) =p(y_{t+1:n}|x_t) \cdot  p(x_t, y_{1:t})​$，因此只需要根据 forward 和 backward算法求得 $p(y_{t+1:n}, x_t) ​$ 和 $p(y_{t+1:n}|x_t)​$ 就可以得到 $p(x_t|y_{1:n})​$

有：

$p(x_t, y_{1:n}) = (\prod_{i=t}^1\mathbf{O_{y_i}} T^t) \mathbf{f_{0:0}} \cdot \prod_{i=t}^n(T\mathbf{O_{y_i}}) \mathbf{1}$

## 测试Smoothing算法 

考虑一个有3个状态的Markov链，

状态转移矩阵（transition matrix)  $T = \begin{bmatrix}0.8 & 0.1 & 0.1 \\ 0.8 & 0.1 & 0.1 \\ 0.1 & 0.8 & 0.1\end{bmatrix}$，

观测状态矩阵（omission matrix)  $O = \begin{bmatrix} 0.5 & 0.3 & 0.2 \\  0.1 & 0.7 & 0.2 \\ 0.1 & 0. 1 & 0. 8 \end{bmatrix}$

并且假设初始的状态分布为 $\pi^T = \begin{bmatrix}0.5 \\ 0.3 \\ 0.2\end{bmatrix}​$

现在我们求 $p(y_{1:3}|x_2) = p(y_1 =1, y_2 = 1, y_3 = 2|x_2)$ 

Python代码如下：

生成转移矩阵和观测矩阵，以及初始状态分布

```
import numpy as np
mat_t = np.mat([[0.8,0.1,0.1],[0.8,0.1,0.1],[0.1,0.8,0.1]])
mat_o = np.mat([[0.5,0.3,0.2],[0.1,0.7,0.2],[0.1,0.1,0.8]])
initial_state = np.mat([[0.5, 0.3, 0.2]])
```

通过多次试验模拟 $p(y_{1:n}|x_t)$ 

```python
def get_probality(ys, xi, exp_time=1000):
    length = len(ys)
    xs = [0, 0, 0]
    for i in range(exp_time):
        seq = get_random_sequence(length)
        if np.array_equal(seq[:, 1], ys):
            xs[seq[xi, 0]] += 1
    return np.array(xs)
```

模拟 $p(y_1=0,y_2=2,y_3=2|x_3)$

```python
ps = get_probality([0,2,2], 2, exp_time=100000)
ps / sum(ps)
# array([0.46116505, 0.23341424, 0.30542071])
```

通过上面的公式计算：

```python
o0 = np.mat(np.diag(mat_o.getA()[:,0]))
o1 = np.mat(np.diag(mat_o.getA()[:,1]))
o2 = np.mat(np.diag(mat_o.getA()[:,2])) 
ps = o2*mat_t.T*o2*mat_t.T*o0*mat_t.T*initial_state.T
ps / sum(ps)
# matrix([[0.44970414],
#         [0.24260355],
#         [0.30769231]])
```

可以看到我们的 forward 算法的结论是正确的

模拟 $p(y_1=0,y_2=2,y_3=1,y_4=1|x_3)$ 并验证之：

```python
ps = get_probality([0,2,1,1], 2, exp_time=100000)
ps / sum(ps)
# array([0.41142384, 0.54884106, 0.0397351 ])
ps = np.multiply(o1*mat_t.T*o2*mat_t.T*o0*mat_t.T*initial_state.T, o1*mat_t*np.mat(np.ones([3,1])))
ps / sum(ps)
# matrix([[0.42271147],
#         [0.53209733],
#         [0.04519119]])
```

可见forward-backward的算法也是准确的

